{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading boston data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "df_bos=pd.DataFrame(boston.data)\n",
    "df_bos.columns = boston.feature_names\n",
    "df_bos['PRICE'] = boston.target\n",
    "df_bos.head()\n",
    "df_bos.to_csv(\"housing1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    dataset = pd.read_csv(filename)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  \\\n",
       "0           0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0   \n",
       "1           1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0   \n",
       "2           2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0   \n",
       "3           3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0   \n",
       "4           4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0   \n",
       "\n",
       "     TAX  PTRATIO       B  LSTAT  PRICE  \n",
       "0  296.0     15.3  396.90   4.98   24.0  \n",
       "1  242.0     17.8  396.90   9.14   21.6  \n",
       "2  242.0     17.8  392.83   4.03   34.7  \n",
       "3  222.0     18.7  394.63   2.94   33.4  \n",
       "4  222.0     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = load_csv(\"/home/srikar/housing1.csv\")\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression(x_train, y_train, lam, kernel, sigma):\n",
    "    K = np.empty([len(x_train), len(x_train)])\n",
    "    lambda_identity = np.identity(len(x_train))\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(len(x_train)):\n",
    "            if kernel == linear:\n",
    "                K[i, j] = linear(x_train[i], x_train[j])\n",
    "            elif kernel == polynomial:\n",
    "                K[i, j] = polynomial(x_train, gamma, r, M)\n",
    "            else:\n",
    "                K[i, j] = gauss(x_train[i], x_train[j], sigma)\n",
    "\n",
    "    theInverse = np.linalg.inv(K + lambda_identity)\n",
    "    w = np.dot(theInverse, y_train)\n",
    "    return w\n",
    "\n",
    "# def regression_Linear(x_train, y_train, lam, kernel, sigma):\n",
    "#     K = np.empty([len(x_train), len(x_train)])\n",
    "#     lambda_identity = np.identity(len(x_train))\n",
    "\n",
    "#     for i in range(len(x_train)):\n",
    "#         for j in range(len(x_train)):\n",
    "#             K[i, j] = linear(x_train[i], x_train[j])\n",
    "            \n",
    "#     theInverse = np.linalg.inv(K + lambda_identity)\n",
    "#     wL = np.dot(theInverse, y_train)\n",
    "#     return wL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def regression_poly(x_train, y_train, lam, kernel, sigma):\n",
    "#     K = np.empty([len(x_train), len(x_train)])\n",
    "#     lambda_identity = np.identity(len(x_train))\n",
    "\n",
    "#     for i in range(len(x_train)):\n",
    "#         for j in range(len(x_train)):\n",
    "#                   K[i, j] = polynomial(x_train, gamma, r, M)\n",
    "            \n",
    "\n",
    "#     theInverse = np.linalg.inv(K + lambda_identity)\n",
    "#     wP = np.dot(theInverse, y_train)\n",
    "#     return wP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def regression_Gauss(x_train, y_train, lam, kernel, sigma):\n",
    "#     K = np.empty([len(x_train), len(x_train)])\n",
    "#     lambda_identity = np.identity(len(x_train))\n",
    "\n",
    "#     for i in range(len(x_train)):\n",
    "#         for j in range(len(x_train)):\n",
    "#             K[i, j] = gauss(x_train[i], x_train[j], sigma)\n",
    "\n",
    "#     theInverse = np.linalg.inv(K + lambda_identity)\n",
    "#     wG = np.dot(theInverse, y_train)\n",
    "#     return wG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(X, Xprime):\n",
    "    return np.dot(np.transpose(X), Xprime)\n",
    "\n",
    "\n",
    "def polynomial(X, xprime, gamma, r, M):\n",
    "    return (np.dot(np.dot(gamma, np.transpose(x)), xprime) + r) ** M\n",
    "\n",
    "\n",
    "def gauss(x, xprime, sigma):\n",
    "    x = x - xprime\n",
    "    return np.exp(-(np.linalg.norm(x) ** 2) / (2 * (sigma) ** 2))\n",
    "\n",
    "\n",
    "def kfold(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_bos[['RM', 'LSTAT', 'DIS','PRICE']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\t\tINDUS\tx\t\tRM\t\tDIS\tRAD\tTAX\t\tB\tLSTAT\tPRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def predict(dataset, kernel, lam, **kwargs):\n",
    "#     folds = kfold(dataset)\n",
    "#     for train_index, test_index in folds.split(dataset):\n",
    "\n",
    "#             x_train = np.asarray([[row['RM'], row['LSTAT'], row['DIS'],\n",
    "#                                    row['CRIM'], row['ZN'], row['INDUS'], row['NOX'], row['AGE'], row['PTRATIO']] for index, row in dataset.iloc[train_index].iterrows()])\n",
    "#             x_test = np.asarray([[row['RM'], row['LSTAT'], row['DIS'],\n",
    "#                                    row['CRIM'], row['ZN'], row['INDUS'], row['NOX'], row['AGE'], row['PTRATIO']] for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "#             y_train = np.asarray([[row['PRICE']]\n",
    "#                                   for index, row in dataset.iloc[train_index].iterrows()])\n",
    "\n",
    "#             y_test = np.asarray([[row['PRICE']]\n",
    "#                                  for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "#             w = regression(x_train, y_train, lam, kernel)\n",
    "#             predicted = []\n",
    "\n",
    "#             for i in range(len(x_test)):\n",
    "#                 k = np.empty(len(x_train))\n",
    "#                 for j in range(len(x_train)):\n",
    "#                     k[i] = kernel(x_train[j], x_test[i])\n",
    "#                 prediction = np.dot(k, w)\n",
    "#                 predicted.append(prediction)\n",
    "\n",
    "#             predicted = np.asarray(predicted)\n",
    "#             error = mean_squared_error(y_test, predicted)\n",
    "#             print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(dataset, kernel, lam, **kwargs):\n",
    "    folds = kfold(dataset)\n",
    "    if kernel == linear:\n",
    "        for train_index, test_index in folds.split(dataset):\n",
    "\n",
    "            x_train = np.asarray([[row['RM'], row['LSTAT'], row['DIS']]  for index, row in dataset.iloc[train_index].iterrows()])\n",
    "            x_test = np.asarray([[row['RM'], row['LSTAT'], row['DIS']]  for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "            y_train = np.asarray([[row['PRICE']]\n",
    "                                  for index, row in dataset.iloc[train_index].iterrows()])\n",
    "\n",
    "            y_test = np.asarray([[row['PRICE']]\n",
    "                                 for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "            w = regression(x_train, y_train, lam, kernel)\n",
    "            predicted = []\n",
    "\n",
    "            for i in range(len(x_test)):\n",
    "                k = np.empty(len(x_train))\n",
    "                for j in range(len(x_train)):\n",
    "                    k[i] = kernel(x_train[j], x_test[i])\n",
    "                prediction = np.dot(k, w)\n",
    "                predicted.append(prediction)\n",
    "\n",
    "            predicted = np.asarray(predicted)\n",
    "            error = mean_squared_error(y_test, predicted)\n",
    "            print(error)\n",
    "\n",
    "    if kernel == polynomial:\n",
    "        gamma = kwargs['gamma']\n",
    "        r = kwargs['r']\n",
    "        M = kwargs['M']\n",
    "\n",
    "        for train_index, test_index in folds.split(dataset):\n",
    "\n",
    "            x_train = np.asarray([[row['RM'], row['LSTAT'], row['DIS']]  for index, row in dataset.iloc[train_index].iterrows()])\n",
    "            x_test = np.asarray([[row['RM'], row['LSTAT'], row['DIS']]  for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "            y_train = np.asarray([[row['PRICE']]\n",
    "                                  for index, row in dataset.iloc[train_index].iterrows()])\n",
    "\n",
    "            y_test = np.asarray([[row['PRICE']]\n",
    "                                 for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "            w = regression(x_train, y_train, lam, kernel, gamma, r, M)\n",
    "\n",
    "            predicted = []\n",
    "\n",
    "            for i in range(len(x_test)):\n",
    "                k = np.empty(len(x_train))\n",
    "                for j in range(len(x_train)):\n",
    "                    k[i] = kernel(x_train[j], x_test[i])\n",
    "                    prediction = np.dot(np.transpose(k), w)\n",
    "                    predicted.append(prediction)\n",
    "\n",
    "                predicted = np.asarray()\n",
    "\n",
    "    if kernel == gauss:\n",
    "        sigma = 10\n",
    "\n",
    "        for train_index, test_index in folds.split(dataset):\n",
    "\n",
    "            x_train = np.asarray([[row['RM'], row['LSTAT'], row['DIS']]  for index, row in dataset.iloc[train_index].iterrows()])\n",
    "            x_test = np.asarray([[row['RM'], row['LSTAT'], row['DIS']]  for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "            y_train = np.asarray([[row['PRICE']]\n",
    "                                  for index, row in dataset.iloc[train_index].iterrows()])\n",
    "\n",
    "            y_test = np.asarray([[row['PRICE']]\n",
    "                                 for index, row in dataset.iloc[test_index].iterrows()])\n",
    "\n",
    "            w = regression(x_train, y_train, lam, kernel, sigma)\n",
    "            predicted = []\n",
    "\n",
    "            for i in range(len(x_test)):\n",
    "                k = np.empty(len(x_train))\n",
    "                for j in range(len(x_train)):\n",
    "                    k[i] = kernel(x_train[j], x_test[i], sigma)\n",
    "                prediction = np.dot(k, w)\n",
    "                predicted.append(prediction)\n",
    "\n",
    "            predicted = np.asarray(predicted)\n",
    "            #print(predicted)\n",
    "            error = mean_squared_error(y_test, predicted)\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231.8348742\n",
      "6448096.11942\n",
      "11831981.9242\n",
      "4603118.64104\n",
      "2762649.97761\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/srikar/housing1.csv\"\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "predict(dataset, gauss, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"/home/srikar/housing1.csv\"\n",
    "dataset = load_csv(filename)\n",
    "predict(dataset,polynomial , 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Refactored Code------>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    dataset = pd.read_csv(filename)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regr_lin(params):\n",
    "    x_train, y_train = params[0], params[1]\n",
    "    K = np.empty([len(x_train), len(x_train)])\n",
    "    lambda_identity = np.identity(len(x_train))\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(len(x_train)):\n",
    "            K[i, j] = linear(x_train[i], x_train[j])\n",
    "    theInverse = np.linalg.inv(K + lambda_identity)\n",
    "    w = np.dot(theInverse, y_train)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regr_poly(params):\n",
    "    x_train, y_train, gamma, r, M = params[0], params[1], params[2], params[3], params[4]\n",
    "    K = np.empty([len(x_train), len(x_train)])\n",
    "    lambda_identity = np.identity(len(x_train))\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(len(x_train)):\n",
    "            K[i, j] = polynomial(x_train[i], x_train[j], gamma, r, M)\n",
    "    theInverse = np.linalg.inv(K + lambda_identity)\n",
    "    w = np.dot(theInverse, y_train)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regr_gauss(params):\n",
    "    x_train, y_train, sigma = params[0], params[1], params[2]\n",
    "    K = np.empty([len(x_train), len(x_train)])\n",
    "    lambda_identity = np.identity(len(x_train))\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(len(x_train)):\n",
    "            K[i, j] = gauss(x_train[i], x_train[j], sigma)\n",
    "    theInverse = np.linalg.inv(K + lambda_identity)\n",
    "    w = np.dot(theInverse, y_train)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(X, Xprime):\n",
    "    return np.dot(np.transpose(X), Xprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial(X, xprime, gamma, r, M):\n",
    "    return (np.dot(np.dot(gamma, np.transpose(X)), xprime) + r) ** M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, xprime, sigma):\n",
    "    x = x - xprime\n",
    "    return np.exp(-(np.linalg.norm(x) ** 2) / (2 * (sigma) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold(dataset):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random.randint(1, 10))\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataset):\n",
    "    for train_index, test_index in folds.split(dataset):\n",
    "        \n",
    "        x_train = np.asarray([[row['RM'], row['LSTAT'], row['DIS']] for index, row in dataset.iloc[train_index].iterrows()])        \n",
    "        \n",
    "        x_test = np.asarray([[row['RM'], row['LSTAT'], row['DIS']] for index, row in dataset.iloc[test_index].iterrows()])\n",
    "        \n",
    "        y_train = np.asarray([[row['PRICE']] for index, row in dataset.iloc[train_index].iterrows()])\n",
    "    \n",
    "        y_test = np.asarray([[row['PRICE']] for index, row in dataset.iloc[test_index].iterrows()])\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_lin(params):\n",
    "    \n",
    "    dataset = params[0]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset)\n",
    "    \n",
    "    w = regr_lin([x_train, y_train])\n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        k = np.empty(len(x_train))\n",
    "        for j in range(len(x_train)):\n",
    "            k[i] = linear(x_train[j], x_test[i])\n",
    "        prediction = np.dot(k, w)\n",
    "        predicted.append(prediction)\n",
    "        \n",
    "    predicted = np.asarray(predicted)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    acc_score = r2_score(y_test, predicted) * 100\n",
    "    \n",
    "    return mse, acc_score, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_poly(params):\n",
    "    \n",
    "    dataset, gamma, r, M = params[0], params[1], params[2], params[3]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset)\n",
    "    \n",
    "    w = regr_poly([x_train, y_train, gamma, r, M])\n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        k = np.empty(len(x_train))\n",
    "        for j in range(len(x_train)):\n",
    "            k[i] = polynomial(x_train[j], x_test[i], gamma, r, M)\n",
    "        prediction = np.dot(np.transpose(k), w)\n",
    "        predicted.append(prediction)\n",
    "        \n",
    "    predicted = np.asarray(predicted)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    acc_score = r2_score(y_test, predicted) * 100\n",
    "    \n",
    "    return mse, acc_score, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_gauss(params):\n",
    "    \n",
    "    dataset, sigma = params[0], params[1]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset)\n",
    "    \n",
    "    w = regr_gauss([x_train, y_train, sigma])\n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        k = np.empty(len(x_train))\n",
    "        for j in range(len(x_train)):\n",
    "            k[i] = gauss(x_train[j], x_test[i], sigma)\n",
    "        prediction = np.dot(k, w)\n",
    "        predicted.append(prediction)\n",
    "        \n",
    "    predicted = np.asarray(predicted)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    acc_score = r2_score(y_test, predicted) * 100\n",
    "    \n",
    "    return mse, acc_score, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"/home/srikar/housing1.csv\"\n",
    "dataset = load_csv(filename)\n",
    "percent = 0.80\n",
    "dataset_cv = dataset[ : int(percent * dataset.shape[0])]\n",
    "dataset_main = dataset[int(percent * dataset.shape[0]) : ]\n",
    "\n",
    "folds = kfold(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Taken to Tune Hyper Parameter Values = 3.931016039848328 Mins\n"
     ]
    }
   ],
   "source": [
    "tx = time.time()\n",
    "# No Tuning for Linear\n",
    "mse_lin, acc_lin, _ = pred_lin([dataset_cv])\n",
    "# Tuning for Polynomial\n",
    "compare_poly = []\n",
    "for gamma in [1.0, 2.0, 3.0, 4.0, 5.0]:\n",
    "    for r in [1.0, 2.0, 3.0, 4.0, 5.0]:\n",
    "        for M in [3.0, 4.0, 5.0, 6.0, 7.0]:\n",
    "            mse_poly, acc_poly, _ = pred_poly([dataset_cv, gamma, r, M])\n",
    "            compare_poly.append([gamma, r, M, mse_poly, acc_poly])\n",
    "# Tuning for Gaussian\n",
    "compare_gauss = []\n",
    "for sigma in [1.0, 2.0, 3.0, 4.0, 5.0]:\n",
    "    mse_gauss, acc_gauss, _ = pred_gauss([dataset_cv, sigma])\n",
    "    compare_gauss.append([sigma, mse_gauss, acc_gauss])\n",
    "print('\\nTime Taken to Tune Hyper Parameter Values = ' + str((time.time()-tx)/60) + ' Mins')\n",
    "\n",
    "# Saving All Values obtained from Hyper Parameter Tuning\n",
    "compare_poly = np.array(compare_poly)\n",
    "df = pd.DataFrame(compare_poly)\n",
    "df.to_csv(\"polynomial_results_math.csv\")\n",
    "compare_gauss = np.array(compare_gauss)\n",
    "df = pd.DataFrame(compare_gauss)\n",
    "df.to_csv(\"gaussian_results_math.csv\")\n",
    "\n",
    "# Fetching Hyperparameters based on Max Accuracy Score\n",
    "# Polynomial\n",
    "poly_max = np.where(compare_poly[:, 4] == np.amax(compare_poly[:, 4]))\n",
    "poly_gamma = compare_poly[poly_max[0]][0][0]\n",
    "poly_r = compare_poly[poly_max[0]][0][1]\n",
    "poly_M = compare_poly[poly_max[0]][0][2]\n",
    "# Gaussian\n",
    "gauss_max = np.where(compare_gauss[:, 2] == np.amax(compare_gauss[:, 2]))\n",
    "gauss_sigma = compare_gauss[gauss_max[0]][0][0]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Kernel\n",
      "Time Taken to Fit the Model and Predict : 0.23737406730651855 Secs\n",
      "Accuracy Score of the Model : -61197375.23\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (101,) and (20, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3e09629c6be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Linear Kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_lin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Linear Kernel - Y_test vs. Y_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/srikar/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3316\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3318\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3319\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/srikar/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/srikar/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/srikar/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/srikar/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/srikar/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (101,) and (20, 1)"
     ]
    }
   ],
   "source": [
    "print('\\nLinear Kernel')\n",
    "t = time.time()\n",
    "mse_lin, acc_lin, preds_lin = pred_lin([dataset_main])\n",
    "lin_t = time.time() - t\n",
    "print('Time Taken to Fit the Model and Predict : ' + str(lin_t) + ' Secs')\n",
    "print('Accuracy Score of the Model : ' + str(acc_lin))\n",
    "plt.figure('Linear Kernel')\n",
    "plt.plot([x for x in range(0, len(y_test))], y_test, 'b.')\n",
    "plt.plot([x for x in range(0, len(y_test))], preds_lin, 'r.')\n",
    "plt.title('Linear Kernel - Y_test vs. Y_pred')\n",
    "plt.legend(['Y_test', 'Y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
